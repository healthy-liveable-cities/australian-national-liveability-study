{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedestrian street networks for 21 cities\n",
    "Using OpenStreetMap as a source for \n",
    "* complete road network, and \n",
    "* a pedestrian 'walk/cycle'network. \n",
    "* calculating intersection density for the pedestrian network\n",
    "\n",
    "The process iterates over a list of city names, whose 10km buffered boundary shape files have been pre-prepared.\n",
    "\n",
    "Carl Higgs\n",
    "1 October 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OSM set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used for OSM conversion\n",
    "import os\n",
    "import sys\n",
    "import subprocess as sp\n",
    "from datetime import datetime\n",
    "\n",
    "# Libraries used for OSMnx analyses and output\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import requests\n",
    "import fiona\n",
    "ox.config(use_cache=True, log_console=True)\n",
    "ox.__version__\n",
    "\n",
    "from shapely.geometry import shape, MultiPolygon, Polygon\n",
    "\n",
    "# define pedestrian network custom filter (based on OSMnx 'walk' network type, without the cycling exclusion)\n",
    "pedestrian = (\n",
    "             '[\"area\"!~\"yes\"]' \n",
    "             '[\"highway\"!~\"motor|proposed|construction|abandoned|platform|raceway\"]'\n",
    "             '[\"foot\"!~\"no\"]'  \n",
    "             '[\"service\"!~\"private\"]' \n",
    "             '[\"access\"!~\"private\"]'\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract OSM using 10km buffered study region .poly files\n",
    "\n",
    "The idea with this step is to extract OSM for each buffered study region, and then this file would be used to build the all non-private roads, and pedestrian roads networks.  However there is apparently a bug with the OSMnx 'graph_from_file' command; as such, OSMnx networks were constructed using the OSM version current on Overpass.de at date of processing (2/10/2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".osm file D:/ntnl_li_2018_template/data/study_region/adelaide/adelaide_gccsa_2016_10000m_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/albury_wodonga/AlburyWodonga_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/ballarat/Ballarat_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/bendigo/Bendigo_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/bris/bris_gccsa_2016_10000m_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/cairns/Cairns_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/canberra/canberra_gccsa_2016_10000m_20181001.osm already exists\n",
      " Extraction of .osm file for darwin_gccsa_2016_10000m complete in 19.9 minutes.\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/geelong/Geelong_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/goldcoast_tweedheads/GoldCoast_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/hobart/hobart_gccsa_2016_10000m_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/launceston/Launceston_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/mackay/Mackay_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/melb/melb_gccsa_2016_10000m_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/mitchell/mitchell_lga_2016_10000m_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/newcastle_maitland/Newcastle_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/perth/perth_gccsa_2016_10000m_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/sunshine_coast/SunshineCoast_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/syd/syd_gccsa_2016_10000m_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/toowoomba/Toowoomba_20181001.osm already exists\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/townsville/Townsville_20181001.osm already exists\n",
      " Extraction of .osm file for WesternSydney complete in 19.8 minutes.\n",
      ".osm file D:/ntnl_li_2018_template/data/study_region/wollongong/Wollongong_20181001.osm already exists\n",
      "\n",
      "Extracted (or attempted to extract) 2 OSM portions.\n",
      "Elapsed time was 39.7 minutes\n"
     ]
    }
   ],
   "source": [
    "# iterate of files within root or otherwise specified directory, noting all poly files\n",
    "\n",
    "# location of source OSM file\n",
    "osm_dir = 'D:/osm/planet_archives/planet-latest_20181001.osm.pbf'\n",
    "\n",
    "# location of boundary files to iterate over\n",
    "search_dir = 'D:/ntnl_li_2018_template/data/study_region/'\n",
    "\n",
    "# conversion settings\n",
    "exe = 'osmconvert64-0.8.8p.exe'\n",
    "exepath = 'D:/osm/'\n",
    "osm_format = 'osm'\n",
    "\n",
    "# output suffix\n",
    "suffix = '_20181001'\n",
    "\n",
    "count = 0\n",
    "# Start timing the code\n",
    "start_time = datetime.now()\n",
    "for root, dirs, files in os.walk(search_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".poly\"):\n",
    "           # Extract OSM\n",
    "           subtime = datetime.now()\n",
    "           fullfile = os.path.join(root,file)\n",
    "           filename = os.path.splitext(file)[0]\n",
    "           studyregion = '{root}/{filename}{suffix}.{osm_format}'.format(root = root,\n",
    "                                                                         filename = filename,\n",
    "                                                                         suffix = suffix,\n",
    "                                                                         osm_format = osm_format)\n",
    "           if os.path.isfile('{}'.format(studyregion)):\n",
    "             print('.osm file {} already exists'.format(studyregion))\n",
    "            \n",
    "           if not os.path.isfile('{}'.format(studyregion)):\n",
    "             command = '{osmconvert} {osm} -B={poly} -o={studyregion}'.format(osmconvert = exe, \n",
    "                                                                            osm = osm_dir,\n",
    "                                                                            poly = fullfile,\n",
    "                                                                            studyregion = studyregion)\n",
    "             sp.call(command, shell=True, cwd=exepath)\n",
    "             count+=1\n",
    "             print(' Extraction of .osm file for {} complete in {:.1f} minutes.'.format(filename,\n",
    "                                                                                  (datetime.now() - subtime).total_seconds()/60))\n",
    "            \n",
    "print('\\nExtracted (or attempted to extract) {} OSM portions.'.format(count))            \n",
    "print(\"Elapsed time was {:.1f} minutes\".format((datetime.now() - start_time).total_seconds()/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osmconvert_0.8.10_largepoly_6000004_x64.exe D:/osm/planet_archives/planet-latest_20181001.osm.pbf -B=D:/ntnl_li_2018_template/data/study_region/australia\\Australia.poly -o=D:/ntnl_li_2018_template/data/study_region/australia/Australia_20181001.osm\n"
     ]
    }
   ],
   "source": [
    "# Extract Australia\n",
    "# location of source OSM file\n",
    "osm_dir = 'D:/osm/planet_archives/planet-latest_20181001.osm.pbf'\n",
    "\n",
    "# location of boundary files to iterate over\n",
    "search_dir = 'D:/ntnl_li_2018_template/data/study_region/australia'\n",
    "\n",
    "# conversion settings\n",
    "exe = 'osmconvert_0.8.10_largepoly_6000004_x64.exe'\n",
    "exepath = 'D:/osm/osmctools/src/'\n",
    "osm_format = 'osm'\n",
    "\n",
    "# output suffix\n",
    "suffix = '_20181001'\n",
    "\n",
    "count = 0\n",
    "# Start timing the code\n",
    "start_time = datetime.now()\n",
    "for root, dirs, files in os.walk(search_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".poly\"):\n",
    "           # Extract OSM\n",
    "           subtime = datetime.now()\n",
    "           fullfile = os.path.join(root,file)\n",
    "           filename = os.path.splitext(file)[0]\n",
    "           studyregion = '{root}/{filename}{suffix}.{osm_format}'.format(root = root,\n",
    "                                                                         filename = filename,\n",
    "                                                                         suffix = suffix,\n",
    "                                                                         osm_format = osm_format)\n",
    "           if os.path.isfile('{}'.format(studyregion)):\n",
    "             print('.osm file {} already exists'.format(studyregion))\n",
    "            \n",
    "           if not os.path.isfile('{}'.format(studyregion)):\n",
    "             command = '{osmconvert} {osm} -B={poly} -o={studyregion}'.format(osmconvert = exe, \n",
    "                                                                            osm = osm_dir,\n",
    "                                                                            poly = fullfile,\n",
    "                                                                            studyregion = studyregion)\n",
    "             print(command)\n",
    "             sp.call(command, shell=True, cwd=exepath)\n",
    "             count+=1\n",
    "             print(' Extraction of .osm file for {} complete in {:.1f} minutes.'.format(filename,\n",
    "                                                                                        (datetime.now() - subtime).total_seconds()/60))\n",
    "\n",
    "            \n",
    "print('\\nExtracted (or attempted to extract) {} OSM portions.'.format(count))            \n",
    "print(\"Elapsed time was {:.1f} minutes\".format((datetime.now() - start_time).total_seconds()/60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the '21 cities' directory has since been re-set up as 'study_regions'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get networks and save as graphs (retain_all = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved graph object and shapefile for adelaide_gccsa_2018_10000m_epsg4326 in 23.0 minutes.\n",
      "Saved graph object and shapefile for alburywodonga__sua_2018_10000m_epsg4326 in 2.0 minutes.\n",
      "Saved graph object and shapefile for ballarat__sua_2018_10000m_epsg4326 in 2.6 minutes.\n",
      "Saved graph object and shapefile for bendigo__sua_2018_10000m_epsg4326 in 1.7 minutes.\n",
      "Saved graph object and shapefile for bris_gccsa_2018_10000m_epsg4326 in 24.9 minutes.\n",
      "Saved graph object and shapefile for cairns__sua_2018_10000m_epsg4326 in 1.5 minutes.\n",
      "Saved graph object and shapefile for canberra_gccsa_2018_10000m_epsg4326 in 11.0 minutes.\n",
      "Saved graph object and shapefile for geelong__sua_2018_10000m_epsg4326 in 4.2 minutes.\n",
      "Saved graph object and shapefile for goldcoast__sua_2018_10000m_epsg4326 in 8.8 minutes.\n",
      "Saved graph object and shapefile for hobart_gccsa_2018_10000m_epsg4326 in 3.1 minutes.\n",
      "Saved graph object and shapefile for launceston__sua_2018_10000m_epsg4326 in 1.4 minutes.\n",
      "Saved graph object and shapefile for mackay__sua_2018_10000m_epsg4326 in 0.9 minutes.\n",
      "Saved graph object and shapefile for melb_gccsa_2018_10000m_epsg4326 in 48.2 minutes.\n",
      "Saved graph object and shapefile for mitchell_lga_2018_10000m_epsg4326 in 2.9 minutes.\n",
      "Saved graph object and shapefile for newcastle__sua_2018_10000m_epsg4326 in 5.9 minutes.\n",
      "Saved graph object and shapefile for perth_gccsa_2018_10000m_epsg4326 in 22.0 minutes.\n",
      "Saved graph object and shapefile for sunshinecoast__sua_2018_10000m_epsg4326 in 4.4 minutes.\n",
      "Saved graph object and shapefile for syd_gccsa_2018_10000m_epsg4326 in 35.3 minutes.\n",
      "Saved graph object and shapefile for toowoomba__sua_2018_10000m_epsg4326 in 2.0 minutes.\n",
      "Saved graph object and shapefile for townsville__sua_2018_10000m_epsg4326 in 1.6 minutes.\n",
      "Saved graph object and shapefile for westernsydney__sua_2018_10000m_epsg4326 in 21.0 minutes.\n",
      "Saved graph object and shapefile for wollongong__sua_2018_10000m_epsg4326 in 4.7 minutes.\n",
      "Elapsed time was 440.0 minutes\n"
     ]
    }
   ],
   "source": [
    "# location of boundary files to iterate over\n",
    "search_dir = 'D:/ntnl_li_2018_template/data/study_region/'\n",
    "# output suffix\n",
    "suffix = '_20181001'\n",
    "count = 0\n",
    "for root, dirs, files in os.walk(search_dir):\n",
    "    for file in files:\n",
    "        if \"10kmBuff\" in file: \n",
    "           os.rename(os.path.join(root,file),os.path.join(root,file.replace('10kmBuff','_sua_2018_10000m_epsg4326').lower()))\n",
    "\n",
    "for root, dirs, files in os.walk(search_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"10000m_epsg4326.shp\"): \n",
    "           fullfile = os.path.join(root,file)\n",
    "           filename = os.path.splitext(file)[0]\n",
    "           studyregion = filename.replace('2016','2018')\n",
    "           if os.path.isfile(os.path.join(root,\n",
    "                   'osm_{studyregion}_pedestrian{suffix}'.format(studyregion = studyregion,suffix = suffix))):\n",
    "             print('Pedestrian road network for {} has already been processed'.format(studyregion))\n",
    "           else:\n",
    "             subtime = datetime.now()\n",
    "             # Extract pedestrian network\n",
    "             c = fiona.open(fullfile)   \n",
    "             polygon = shape(next(iter(c))['geometry'])\n",
    "             # Extract  complete non-private OSM network: \"all (non-private) OSM streets and paths\"\n",
    "             W = ox.graph_from_polygon(polygon,  network_type= 'all', retain_all = True)\n",
    "             ox.save_graphml(W, filename=os.path.join(root,\n",
    "                                                           'osm_{studyregion}_all{suffix}.graphml'.format(studyregion = studyregion,\n",
    "                                                                                                       suffix = suffix)), \n",
    "                             folder=None, gephi=False)\n",
    "             ox.save_graph_shapefile(W, \n",
    "                                     filename=os.path.join(root,\n",
    "                                                           'osm_{studyregion}_all{suffix}'.format(studyregion = studyregion,\n",
    "                                                                                                       suffix = suffix)))\n",
    "             W = ox.graph_from_polygon(polygon,  custom_filter= pedestrian, retain_all = True)\n",
    "             ox.save_graphml(W, filename=os.path.join(root,\n",
    "                                                           'osm_{studyregion}_pedestrian{suffix}.graphml'.format(studyregion = studyregion,\n",
    "                                                                                                       suffix = suffix)), \n",
    "                             folder=None, gephi=False)\n",
    "             ox.save_graph_shapefile(W, \n",
    "                                     filename=os.path.join(root,\n",
    "                                                           'osm_{studyregion}_pedestrian{suffix}'.format(studyregion = studyregion,\n",
    "                                                                                                       suffix = suffix)))  \n",
    "             print('Saved graph object and shapefile for {} in {:.1f} minutes.'.format(studyregion,\n",
    "                                                                                    (datetime.now() - subtime).total_seconds()/60))         \n",
    "        count+=1          \n",
    "                 \n",
    "print(\"Elapsed time was {:.1f} minutes\".format((datetime.now() - start_time).total_seconds()/60.0))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Note that the below analyses are tangential and were performed prior to the above **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean intersections for 21 cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time was 5775.9 minutes\n"
     ]
    }
   ],
   "source": [
    "# import geopandas as gp\n",
    "from sqlalchemy import *\n",
    "from geoalchemy2 import Geometry\n",
    "import subprocess as sp\n",
    "# location of boundary files to iterate over\n",
    "search_dir = 'D:/ntnl_li_2018_template/data/study_region'\n",
    "# output suffix\n",
    "suffix = '_20181001'\n",
    "stub = '_pedestrian{suffix}.graphml'.format(suffix = suffix)\n",
    "db = 'li_intersections_2018'\n",
    "user = 'python'\n",
    "pwd = '***REMOVED***'\n",
    "engine = create_engine('postgresql://{}:{}@localhost:5432/{}'.format(user,pwd,db))\n",
    "conn = engine.connect()\n",
    "places = ['\"{}\"'.format(x) for x in engine.table_names() if x not in ['spatial_ref_sys','intersections']]\n",
    "count = 0\n",
    "for root, dirs, files in os.walk(search_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(stub): \n",
    "           fullfile = os.path.join(root,file)\n",
    "           filename = os.path.splitext(file)[0]\n",
    "           studyregion = filename.split('_')[1]\n",
    "           if '\"{}\"'.format(studyregion) not in places and studyregion!='10km':\n",
    "             G = ox.load_graphml(fullfile)\n",
    "             G_proj = ox.project_graph(G)\n",
    "             intersections = ox.clean_intersections(G_proj, tolerance=15, dead_ends=False)\n",
    "             intersections.crs = G_proj.graph['crs']\n",
    "             intersections_latlon = intersections.to_crs(epsg=4326)\n",
    "             # to sql  - works well!\n",
    "\n",
    "             statement = '''\n",
    "               DROP TABLE IF EXISTS {studyregion};\n",
    "               CREATE TABLE {studyregion} (point_4326 geometry);\n",
    "               INSERT INTO {studyregion} (point_4326) VALUES {points};\n",
    "               ALTER TABLE {studyregion} ADD COLUMN geom geometry;\n",
    "               UPDATE {studyregion} SET geom = ST_Transform(point_4326,7845);\n",
    "               ALTER TABLE {studyregion} DROP COLUMN point_4326;\n",
    "             '''.format(studyregion = studyregion,\n",
    "                        points = ', '.join([\"(ST_GeometryFromText('{}',4326))\".format(x.wkt) for x in intersections_latlon]))  \n",
    "             conn.execute(statement)   \n",
    "             places.append('\"{}\"'.format(studyregion))\n",
    "           \n",
    "        count+=1          \n",
    "## output clean intersections for all study regions to geopackage                 \n",
    "command = (\n",
    "          'ogr2ogr -overwrite -f GPKG {dir}/{db}.gpkg '\n",
    "          ' PG:\"host=localhost user={user} dbname={db} password={pwd}\" '\n",
    "          ' {places}'.format(dir = search_dir,\n",
    "                             db = db,\n",
    "                             user = user,\n",
    "                             pwd = pwd,\n",
    "                             places = ' '.join(places))\n",
    "           )\n",
    "sp.call(command)\n",
    "print(\"Elapsed time was {:.1f} minutes\".format((datetime.now() - start_time).total_seconds()/60.0))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following command may not launch from within the Jupyter notebook, but try running it at the command prompt -- seems to work from there!\n",
      "\n",
      "ogr2ogr -overwrite -f GPKG D:/ntnl_li_2018_template/data/study_region/li_intersections_2018.gpkg  PG:\"host=localhost user=python dbname=li_intersections_2018 password=***REMOVED***\"  \"darwin\" \"geelong\" \"canberra\" \"hobart\" \"goldcoast\" \"launceston\" \"mackay\" \"cairns\" \"melb\" \"mitchell\" \"newcastle\" \"townsville\" \"perth\" \"sunshinecoast\" \"syd\" \"toowoomba\" \"westernsydney\" \"wollongong\" \"adelaide\" \"alburywodonga\" \"ballarat\" \"bendigo\" \"bris\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# location of boundary files to iterate over\n",
    "search_dir = 'D:/ntnl_li_2018_template/data/study_region'\n",
    "# output suffix\n",
    "suffix = '_20181001'\n",
    "db = 'li_intersections_2018'\n",
    "user = 'python'\n",
    "pwd = '***REMOVED***'\n",
    "engine = create_engine('postgresql://{}:{}@localhost:5432/{}'.format(user,pwd,db))\n",
    "conn = engine.connect()\n",
    "places = ['\"{}\"'.format(x) for x in engine.table_names() if x not in ['spatial_ref_sys','intersections']]\n",
    "command = (\n",
    "          'ogr2ogr -overwrite -f GPKG {dir}/{db}.gpkg '\n",
    "          ' PG:\"host=localhost user={user} dbname={db} password={pwd}\" '\n",
    "          ' {places}'.format(dir = search_dir,\n",
    "                             db = db,\n",
    "                             user = user,\n",
    "                             pwd = pwd,\n",
    "                             places = ' '.join(places))\n",
    "           )\n",
    "print(\"The following command may not launch from within the Jupyter notebook, but try running it at the command prompt -- seems to work from there!\\n\\n{}\".format(command))\n",
    "sp.call(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract legacy Brisbane OSM for comparison of Open Space areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extraction of .osm file for bris_gccsa_2016_10000m complete in 0.7 minutes.\n",
      "\n",
      "Extracted (or attempted to extract) 1 OSM portions.\n",
      "Elapsed time was 0.7 minutes\n"
     ]
    }
   ],
   "source": [
    "# iterate of files within root or otherwise specified directory, noting all poly files\n",
    "\n",
    "# location of source OSM file\n",
    "osm_dir = 'D:/osm/planet_archives/planet-180514.osm.pbf'\n",
    "### NOTE! This doesn't work --- the download was corrupted....\n",
    "\n",
    "# location of boundary files to iterate over\n",
    "search_dir = 'D:/ntnl_li_2018_template/data/study_region/bris'\n",
    "\n",
    "# conversion settings\n",
    "exe = 'osmconvert64-0.8.8p.exe'\n",
    "exepath = 'D:/osm/'\n",
    "osm_format = 'osm'\n",
    "\n",
    "# output suffix\n",
    "suffix = '_20181001'\n",
    "\n",
    "count = 0\n",
    "# Start timing the code\n",
    "start_time = datetime.now()\n",
    "for root, dirs, files in os.walk(search_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".poly\"):\n",
    "           # Extract OSM\n",
    "           subtime = datetime.now()\n",
    "           fullfile = os.path.join(root,file)\n",
    "           filename = os.path.splitext(file)[0]\n",
    "           studyregion = '{root}/{filename}{suffix}.{osm_format}'.format(root = root,\n",
    "                                                                         filename = filename,\n",
    "                                                                         suffix = suffix,\n",
    "                                                                         osm_format = osm_format)\n",
    "           if os.path.isfile('{}'.format(studyregion)):\n",
    "             print('.osm file {} already exists'.format(studyregion))\n",
    "            \n",
    "           if not os.path.isfile('{}'.format(studyregion)):\n",
    "             command = '{osmconvert} {osm} -B={poly} -o={studyregion}'.format(osmconvert = exe, \n",
    "                                                                            osm = osm_dir,\n",
    "                                                                            poly = fullfile,\n",
    "                                                                            studyregion = studyregion)\n",
    "             sp.call(command, shell=True, cwd=exepath)\n",
    "             count+=1\n",
    "             print(' Extraction of .osm file for {} complete in {:.1f} minutes.'.format(filename,\n",
    "                                                                                  (datetime.now() - subtime).total_seconds()/60))\n",
    "            \n",
    "print('\\nExtracted (or attempted to extract) {} OSM portions.'.format(count))            \n",
    "print(\"Elapsed time was {:.1f} minutes\".format((datetime.now() - start_time).total_seconds()/60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test brisbane with retain_all = 'True'\n",
    "\n",
    "Does this fix the island issue (Stradbroke networks missing) --- answer = yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved graph object and shapefile for bris_gccsa_2016_10km in 24.8 minutes.\n",
      "Elapsed time was 24.8 minutes\n"
     ]
    }
   ],
   "source": [
    "# iterate of files within root or otherwise specified directory, noting all poly files\n",
    "\n",
    "# location of boundary files to iterate over\n",
    "search_dir = 'D:/ntnl_li_2018_template/data/study_region/bris'\n",
    "\n",
    "# output suffix\n",
    "suffix = '_20181011_retain_all'\n",
    "\n",
    "count = 0\n",
    "# Start timing the code\n",
    "start_time = datetime.now()\n",
    "for root, dirs, files in os.walk(search_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"10000m_epsg4326.shp\"): \n",
    "           subtime = datetime.now()\n",
    "           fullfile = os.path.join(root,file)\n",
    "           filename = os.path.splitext(file)[0]\n",
    "           studyregion = filename.replace('10000m_epsg4326','10km')\n",
    "           # Extract pedestrian network\n",
    "           c = fiona.open(fullfile)   \n",
    "           polygon = shape(next(iter(c))['geometry'])\n",
    "           # Extract  complete non-private OSM network: \"all (non-private) OSM streets and paths\"\n",
    "           W = ox.graph_from_polygon(polygon,  network_type= 'all',retain_all ='True')\n",
    "           ox.save_graphml(W, filename=os.path.join(root,\n",
    "                                                         'osm_10km_{studyregion}_all{suffix}.graphml'.format(studyregion = studyregion,\n",
    "                                                                                                     suffix = suffix)), \n",
    "                           folder=None, gephi=False)\n",
    "           ox.save_graph_shapefile(W, \n",
    "                                   filename=os.path.join(root,\n",
    "                                                         'osm_10km_{studyregion}_all{suffix}'.format(studyregion = studyregion,\n",
    "                                                                                                     suffix = suffix))) \n",
    "           W = ox.graph_from_polygon(polygon,  custom_filter= pedestrian,retain_all ='True')\n",
    "           ox.save_graphml(W, filename=os.path.join(root,\n",
    "                                                         'osm_10km_{studyregion}_pedestrian{suffix}.graphml'.format(studyregion = studyregion,\n",
    "                                                                                                     suffix = suffix)), \n",
    "                           folder=None, gephi=False)\n",
    "           ox.save_graph_shapefile(W, \n",
    "                                   filename=os.path.join(root,\n",
    "                                                         'osm_10km_{studyregion}_pedestrian{suffix}'.format(studyregion = studyregion,\n",
    "                                                                                                     suffix = suffix))) \n",
    "           print('Saved graph object and shapefile for {} in {:.1f} minutes.'.format(studyregion,\n",
    "                                                                                  (datetime.now() - subtime).total_seconds()/60))         \n",
    "           count+=1          \n",
    "                 \n",
    "print(\"Elapsed time was {:.1f} minutes\".format((datetime.now() - start_time).total_seconds()/60.0))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test brisbane with clean_periphery = 'False'\n",
    "Does this fix the island issue (Stradbroke networks missing) --- No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved graph object and shapefile for bris_gccsa_2016_10km in 25.2 minutes.\n",
      "Elapsed time was 25.2 minutes\n"
     ]
    }
   ],
   "source": [
    "# iterate of files within root or otherwise specified directory, noting all poly files\n",
    "\n",
    "# location of boundary files to iterate over\n",
    "search_dir = 'D:/ntnl_li_2018_template/data/study_region/bris'\n",
    "\n",
    "# output suffix\n",
    "suffix = '_20181011_no_clean_periphery'\n",
    "\n",
    "count = 0\n",
    "# Start timing the code\n",
    "start_time = datetime.now()\n",
    "for root, dirs, files in os.walk(search_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"10000m_epsg4326.shp\"): \n",
    "           subtime = datetime.now()\n",
    "           fullfile = os.path.join(root,file)\n",
    "           filename = os.path.splitext(file)[0]\n",
    "           studyregion = filename.replace('10000m_epsg4326','10km')\n",
    "           # Extract pedestrian network\n",
    "           c = fiona.open(fullfile)   \n",
    "           polygon = shape(next(iter(c))['geometry'])\n",
    "           # Extract  complete non-private OSM network: \"all (non-private) OSM streets and paths\"\n",
    "           W = ox.graph_from_polygon(polygon,  network_type= 'all',clean_periphery ='False')\n",
    "           ox.save_graphml(W, filename=os.path.join(root,\n",
    "                                                         'osm_10km_{studyregion}_all{suffix}.graphml'.format(studyregion = studyregion,\n",
    "                                                                                                     suffix = suffix)), \n",
    "                           folder=None, gephi=False)\n",
    "           ox.save_graph_shapefile(W, \n",
    "                                   filename=os.path.join(root,\n",
    "                                                         'osm_10km_{studyregion}_all{suffix}'.format(studyregion = studyregion,\n",
    "                                                                                                     suffix = suffix))) \n",
    "           W = ox.graph_from_polygon(polygon,  custom_filter= pedestrian,clean_periphery ='False')\n",
    "           ox.save_graphml(W, filename=os.path.join(root,\n",
    "                                                         'osm_10km_{studyregion}_pedestrian{suffix}.graphml'.format(studyregion = studyregion,\n",
    "                                                                                                     suffix = suffix)), \n",
    "                           folder=None, gephi=False)\n",
    "           ox.save_graph_shapefile(W, \n",
    "                                   filename=os.path.join(root,\n",
    "                                                         'osm_10km_{studyregion}_pedestrian{suffix}'.format(studyregion = studyregion,\n",
    "                                                                                                     suffix = suffix))) \n",
    "           print('Saved graph object and shapefile for {} in {:.1f} minutes.'.format(studyregion,\n",
    "                                                                                  (datetime.now() - subtime).total_seconds()/60))         \n",
    "           count+=1          \n",
    "                 \n",
    "print(\"Elapsed time was {:.1f} minutes\".format((datetime.now() - start_time).total_seconds()/60.0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osmnx",
   "language": "python",
   "name": "osmnx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
